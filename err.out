
OK
Time taken: 1.006 seconds
Query ID = ubuntu_20160922221618_57bb5e57-03d9-4c31-9c41-2e32d8b4cf7f
Total jobs = 9
Stage-16 is filtered out by condition resolver.
Stage-17 is filtered out by condition resolver.
Stage-1 is selected by condition resolver.
Launching Job 1 out of 9
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474581719976_0007, Tracking URL = http://vm1:8088/proxy/application_1474581719976_0007/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474581719976_0007
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 1
2016-09-22 22:16:29,691 Stage-1 map = 0%,  reduce = 0%
2016-09-22 22:16:34,929 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 1.6 sec
2016-09-22 22:16:35,973 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.33 sec
2016-09-22 22:16:42,188 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 4.57 sec
MapReduce Total cumulative CPU time: 4 seconds 570 msec
Ended Job = job_1474581719976_0007
Stage-14 is filtered out by condition resolver.
Stage-15 is selected by condition resolver.
Stage-2 is filtered out by condition resolver.
Execution log at: /tmp/ubuntu/ubuntu_20160922221618_57bb5e57-03d9-4c31-9c41-2e32d8b4cf7f.log
2016-09-22 22:16:46	Starting to launch local task to process map join;	maximum memory = 932184064
2016-09-22 22:16:47	Dump the side-table for tag: 0 with group count: 0 into file: file:/tmp/ubuntu/b1496026-7f53-4831-92ae-07f58eebdfd8/hive_2016-09-22_22-16-18_185_2850107197646421599-1/-local-10010/HashTable-Stage-9/MapJoin-mapfile10--.hashtable
2016-09-22 22:16:47	Uploaded 1 File to: file:/tmp/ubuntu/b1496026-7f53-4831-92ae-07f58eebdfd8/hive_2016-09-22_22-16-18_185_2850107197646421599-1/-local-10010/HashTable-Stage-9/MapJoin-mapfile10--.hashtable (260 bytes)
2016-09-22 22:16:47	End of local task; Time Taken: 0.945 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 3 out of 9
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1474581719976_0008, Tracking URL = http://vm1:8088/proxy/application_1474581719976_0008/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474581719976_0008
Hadoop job information for Stage-9: number of mappers: 1; number of reducers: 0
2016-09-22 22:16:53,578 Stage-9 map = 0%,  reduce = 0%
2016-09-22 22:16:59,795 Stage-9 map = 100%,  reduce = 0%, Cumulative CPU 1.68 sec
MapReduce Total cumulative CPU time: 1 seconds 680 msec
Ended Job = job_1474581719976_0008
Launching Job 4 out of 9
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474581719976_0009, Tracking URL = http://vm1:8088/proxy/application_1474581719976_0009/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474581719976_0009
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2016-09-22 22:17:06,041 Stage-3 map = 0%,  reduce = 0%
2016-09-22 22:17:11,206 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.13 sec
2016-09-22 22:17:18,423 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 2.36 sec
MapReduce Total cumulative CPU time: 2 seconds 360 msec
Ended Job = job_1474581719976_0009
Launching Job 5 out of 9
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474581719976_0010, Tracking URL = http://vm1:8088/proxy/application_1474581719976_0010/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474581719976_0010
Hadoop job information for Stage-4: number of mappers: 1; number of reducers: 1
2016-09-22 22:17:24,508 Stage-4 map = 0%,  reduce = 0%
2016-09-22 22:17:30,700 Stage-4 map = 100%,  reduce = 0%, Cumulative CPU 1.16 sec
2016-09-22 22:17:35,890 Stage-4 map = 100%,  reduce = 100%, Cumulative CPU 2.77 sec
MapReduce Total cumulative CPU time: 2 seconds 770 msec
Ended Job = job_1474581719976_0010
Launching Job 6 out of 9
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1474581719976_0011, Tracking URL = http://vm1:8088/proxy/application_1474581719976_0011/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1474581719976_0011
Hadoop job information for Stage-5: number of mappers: 1; number of reducers: 1
2016-09-22 22:17:41,803 Stage-5 map = 0%,  reduce = 0%
2016-09-22 22:17:48,004 Stage-5 map = 100%,  reduce = 0%, Cumulative CPU 1.1 sec
2016-09-22 22:17:53,194 Stage-5 map = 100%,  reduce = 100%, Cumulative CPU 2.16 sec
MapReduce Total cumulative CPU time: 2 seconds 160 msec
Ended Job = job_1474581719976_0011
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 1   Cumulative CPU: 4.57 sec   HDFS Read: 29376 HDFS Write: 96 SUCCESS
Stage-Stage-9: Map: 1   Cumulative CPU: 1.68 sec   HDFS Read: 13614 HDFS Write: 96 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 2.36 sec   HDFS Read: 5799 HDFS Write: 96 SUCCESS
Stage-Stage-4: Map: 1  Reduce: 1   Cumulative CPU: 2.77 sec   HDFS Read: 8813 HDFS Write: 96 SUCCESS
Stage-Stage-5: Map: 1  Reduce: 1   Cumulative CPU: 2.16 sec   HDFS Read: 6249 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 13 seconds 540 msec
OK
Time taken: 96.131 seconds
